{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7faa7b-3588-4536-bc56-abafe5aff250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "# Diagram settings\n",
    "title_font_size = 12\n",
    "axis_font_size = 12\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7649dc27-3636-4f09-8c7e-a5373f942b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize loss functions: MSE vs. MAE vs. Huber\n",
    "def loss_functions_visualize():    \n",
    "    # ---------------------------------------------------\n",
    "    # 1. Visualize MSE, MAE, and Huber Loss\n",
    "    # ---------------------------------------------------\n",
    "    errors = np.linspace(-2, 2, 200)\n",
    "    delta = 1.0  # Huber threshold\n",
    "    \n",
    "    mse = errors**2\n",
    "    mae = np.abs(errors)\n",
    "    huber = np.where(np.abs(errors) <= delta,\n",
    "                     0.5 * errors**2,\n",
    "                     delta * (np.abs(errors) - 0.5 * delta))\n",
    "    \n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(errors, mse, label=\"MSE\", linewidth=2)\n",
    "    plt.plot(errors, mae, label=\"MAE\", linewidth=2)\n",
    "    plt.plot(errors, huber, label=\"Huber (Î´=1)\", linewidth=2)\n",
    "    plt.title(\"Loss Functions vs. Prediction Error\", fontsize=title_font_size)\n",
    "    plt.xlabel(\"Prediction Error (y - Å·)\", fontsize=axis_font_size)\n",
    "    plt.ylabel(\"Loss\", fontsize=axis_font_size)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc99e5-5b08-4ac9-925a-a2a44e4dc7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interactive, FloatSlider, IntSlider, VBox, Label, Layout\n",
    "\n",
    "def linear_reg_loss_demo(num_outliers=50):\n",
    "    # ---------------------------------------------------\n",
    "    # 1. Create a simple regression dataset\n",
    "    # ---------------------------------------------------\n",
    "    n_samples = 500\n",
    "    X, y = make_regression(n_samples=n_samples, n_features=1, noise=15, random_state=42)\n",
    "\n",
    "    # Add outliers controlled by sliders\n",
    "    outlier_indices = np.random.choice(n_samples, num_outliers, replace=False)\n",
    "    y[outlier_indices] += 200 * np.random.randn(num_outliers)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 2. Train models with different loss functions\n",
    "    # ---------------------------------------------------\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    ols = LinearRegression().fit(X_scaled, y)\n",
    "\n",
    "    sgd_mae = SGDRegressor(loss='epsilon_insensitive', epsilon=0.0, \n",
    "                           max_iter=10000, tol=1e-3, random_state=42).fit(X_scaled, y)\n",
    "    \n",
    "    huber_reg = HuberRegressor(epsilon=1.0, max_iter=1000).fit(X_scaled, y)\n",
    "    \n",
    "    # Predictions\n",
    "    x_line = np.linspace(X_scaled.min(), X_scaled.max(), 100).reshape(-1, 1)\n",
    "    y_ols = ols.predict(x_line)\n",
    "    y_mae = sgd_mae.predict(x_line)\n",
    "    y_huber = huber_reg.predict(x_line)\n",
    "    \n",
    "    # ---------------------------------------------------\n",
    "    # 3. Plot results\n",
    "    # ---------------------------------------------------\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(X_scaled, y, color='gray', alpha=0.4, label=\"Data\")\n",
    "    plt.plot(x_line, y_ols, label=\"MSE\", linewidth=2)\n",
    "    plt.plot(x_line, y_mae, label=\"MAE\", linewidth=2)\n",
    "    plt.plot(x_line, y_huber, label=\"Huber\", linewidth=2)\n",
    "    plt.title(\"Effect of Different Loss Functions on Fit\", fontsize=title_font_size)\n",
    "    plt.xlabel(\"Standardized X\", fontsize=axis_font_size)\n",
    "    plt.ylabel(\"y\", fontsize=axis_font_size)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "    # 4. Create clearly labeled, wide sliders inside a titled block\n",
    "    # ---------------------------------------------------\n",
    "def linear_reg_loss_functions_demo_interact():\n",
    "    num_outliers_slider = IntSlider(\n",
    "        value=50, min=0, max=500, step=5,\n",
    "        description=\"Number of Outliers\",\n",
    "        style={'description_width': '150px'},\n",
    "        layout=Layout(width='500px')\n",
    "    )\n",
    "\n",
    "    ui_box = VBox([\n",
    "        Label(value=\"ðŸ“Š Controls\", layout=Layout(margin=\"0 0 0 0\")),\n",
    "    ])\n",
    "\n",
    "    interactive_plot = interactive(\n",
    "        linear_reg_loss_demo,\n",
    "        num_outliers=num_outliers_slider\n",
    "    )\n",
    "\n",
    "    display(ui_box, interactive_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e93104-7774-46bb-97e2-ffe6f259978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, HuberRegressor\n",
    "from ipywidgets import interactive, FloatSlider, IntSlider, VBox, Label, Layout\n",
    "from IPython.display import display\n",
    "\n",
    "def polynomial_regression_loss_demo(num_outliers=50, poly_estimator_degree=3):\n",
    "    # ---------------------------------------------------\n",
    "    # 1. Create nonlinear dataset (quadratic + noise)\n",
    "    # ---------------------------------------------------\n",
    "    np.random.seed(42)\n",
    "    n_samples = 400\n",
    "    X = np.linspace(-3, 3, n_samples).reshape(-1, 1)\n",
    "    y = 3 * X.squeeze()**3 - 3 * X.squeeze()**2 - 4 * X.squeeze() + np.random.randn(n_samples) * 2\n",
    "\n",
    "    # Add outliers\n",
    "    outlier_indices = np.random.choice(n_samples, num_outliers, replace=False)\n",
    "    y[outlier_indices] += 30 * np.random.randn(num_outliers)\n",
    "    \n",
    "    # Polynomial features\n",
    "    poly = PolynomialFeatures(degree=poly_estimator_degree, include_bias=False)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    \n",
    "    # Normalize for fairness\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_poly)\n",
    "    \n",
    "    # ---------------------------------------------------\n",
    "    # 2. Train models with different loss functions\n",
    "    # ---------------------------------------------------\n",
    "    ols = LinearRegression().fit(X_scaled, y)\n",
    "    sgd_mae = SGDRegressor(loss='epsilon_insensitive', epsilon=0.0, \n",
    "                           max_iter=10000, tol=1e-3, random_state=42).fit(X_scaled, y)\n",
    "    huber_reg = HuberRegressor(epsilon=1.0, max_iter=1000).fit(X_scaled, y)\n",
    "    \n",
    "    # ---------------------------------------------------\n",
    "    # 3. Predict on dense grid for smooth curves\n",
    "    # ---------------------------------------------------\n",
    "    X_line = np.linspace(X.min(), X.max(), 200).reshape(-1, 1)\n",
    "    X_line_poly = poly.transform(X_line)\n",
    "    X_line_scaled = scaler.transform(X_line_poly)\n",
    "    \n",
    "    y_ols = ols.predict(X_line_scaled)\n",
    "    y_mae = sgd_mae.predict(X_line_scaled)\n",
    "    y_huber = huber_reg.predict(X_line_scaled)\n",
    "    \n",
    "    # ---------------------------------------------------\n",
    "    # 4. Visualization\n",
    "    # ---------------------------------------------------\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(X, y, color='gray', alpha=0.4, label=\"Data\")\n",
    "    plt.plot(X_line, y_ols, label=\"MSE\", linewidth=2)\n",
    "    plt.plot(X_line, y_mae, label=\"MAE\", linewidth=2)\n",
    "    plt.plot(X_line, y_huber, label=\"Huber\", linewidth=2)\n",
    "    \n",
    "    plt.title(\"Polynomial Regression with Different Loss Functions\", fontsize=16)\n",
    "    plt.xlabel(\"X\", fontsize=14)\n",
    "    plt.ylabel(\"y\", fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 5. Interactive control panel (same style as before)\n",
    "# ---------------------------------------------------\n",
    "def polynomial_regression_loss_demo_interact():\n",
    "    num_outliers_slider = IntSlider(\n",
    "        value=10, min=0, max=200, step=5,\n",
    "        description=\"Number of Outliers\",\n",
    "        style={'description_width': '150px'},\n",
    "        layout=Layout(width='500px')\n",
    "    )\n",
    "\n",
    "    poly_estimator_degree = IntSlider(\n",
    "        value=3, min=1, max=6, step=1,\n",
    "        description=\"Polyn. Estimator Degree\",\n",
    "        style={'description_width': '150px'},\n",
    "        layout=Layout(width='500px')\n",
    "    )\n",
    "\n",
    "    ui_box = VBox([\n",
    "        Label(value=\"ðŸ“Š Controls\", layout=Layout(margin=\"0 0 0 0\")),\n",
    "    ])\n",
    "\n",
    "    interactive_plot = interactive(\n",
    "        polynomial_regression_loss_demo,\n",
    "        num_outliers=num_outliers_slider,\n",
    "        poly_estimator_degree=poly_estimator_degree\n",
    "    )\n",
    "\n",
    "    display(ui_box, interactive_plot)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
