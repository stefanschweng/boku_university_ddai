{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1781162d-2e6b-4739-9962-01f3810916f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ipywidgets import interactive, FloatSlider, VBox, Label, Layout\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def plot_description(text):\n",
    "    print(f\"\\nDescription:\\n{text}\\n\")\n",
    "\n",
    "\n",
    "def multi_class_classification_demo(separation=1.0):\n",
    "    # ---------------------------------------------------\n",
    "    # 1. Create multi-class dataset\n",
    "    # ---------------------------------------------------\n",
    "    np.random.seed(42)\n",
    "    X, y = make_classification(\n",
    "        n_samples=300, n_features=2, n_informative=2, n_redundant=0,\n",
    "        n_classes=3, n_clusters_per_class=1, class_sep=separation, random_state=42\n",
    "    )\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # ---------------------------------------------------\n",
    "    # 2. Train logistic regression model for multi-class\n",
    "    # ---------------------------------------------------\n",
    "    model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # ---------------------------------------------------\n",
    "    # 3. Visualize decision boundaries\n",
    "    # ---------------------------------------------------\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n",
    "    Z_probabilities = model.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "        \n",
    "    Z_max_proba = Z_probabilities.max(axis=1)\n",
    "    Z_max_proba = Z_max_proba.reshape(xx.shape)\n",
    "    \n",
    "    Z_predictions = np.argmax(Z_probabilities, axis=1)\n",
    "    Z_predictions = Z_predictions.reshape(xx.shape)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    plt.suptitle(\"Multi-Class Classification with Logistic Regression\", fontsize=16)\n",
    "    titles = [\"Max. Prediction Probabilities\", \"Model Decision Boundaries\"]\n",
    "    \n",
    "    for i, title in enumerate(titles):\n",
    "        if i == 0:\n",
    "            zz = Z_max_proba\n",
    "            cmap = \"Blues\"\n",
    "        else:\n",
    "            zz = Z_predictions\n",
    "            cmap = \"viridis\"\n",
    "\n",
    "        ax[i].set_title(title, fontsize=12)\n",
    "        ax[i].contourf(xx, yy, zz, cmap=cmap , alpha=0.5)\n",
    "        ax[i].scatter(X[y==0, 0], X[y==0, 1], color=\"blue\", label=\"Class 0\", edgecolor=\"black\", linewidth=0.5)\n",
    "        ax[i].scatter(X[y==1, 0], X[y==1, 1], color=\"red\", label=\"Class 1\", edgecolor=\"black\", linewidth=0.5)\n",
    "        ax[i].scatter(X[y==2, 0], X[y==2, 1], color=\"green\", label=\"Class 2\", edgecolor=\"black\", linewidth=0.5)\n",
    "        ax[i].set_xlabel(\"Feature 1\", fontsize=12)\n",
    "        ax[i].set_ylabel(\"Feature 2\", fontsize=12)\n",
    "        ax[i].legend(title=\"Ground Truth\")\n",
    "        ax[i].grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def multi_class_classification_demo_interact():\n",
    "    plot_description(\"Example for Multi-Class Classification with a logistic regression model trained using the cross-entropy loss function.\"\n",
    "                     \" Training samples are shown in blue (class 0), red (class 1) and green (class 2). The model outputs three probability values,\"\n",
    "                     \" one for each class, based on the sample's input features (Feature 1 & 2).\\n\\n\"\n",
    "                     \"Left plot: The colored background shows the maximum probability value for each combination of Feature 1 & 2. The darker the \"\n",
    "                     \"background, the higher the probability. Notice how the light area (i.e., the model's uncertainty) increases as training samples\"\n",
    "                     \" of different classes mix (play around with the slider below).\\n\\n\"\n",
    "                     \"Right plot: The background colors of this plot show the model decisions (i.e., assignment of input feature combinations to one class).\"\n",
    "                     \" Purple area => Class 0, Turquoise area => Class 1, Yellow area => Class 2.\")\n",
    "    \n",
    "    # --- Interactive control ---\n",
    "    sep_slider = FloatSlider(\n",
    "        value=1.0, min=0.1, max=3.0, step=0.1,\n",
    "        description=\"Move Samples\",\n",
    "        style={'description_width': '150px'},\n",
    "        layout=Layout(width='500px')\n",
    "    )\n",
    "    ui_box = VBox([\n",
    "        Label(value=\"ðŸ“Š Controls\", layout=Layout(margin=\"0 0 0 0\")),\n",
    "    ])\n",
    "    interactive_plot = interactive(multi_class_classification_demo, separation=sep_slider)\n",
    "    display(ui_box, interactive_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbace7e9-5afc-4968-b56c-90cc9ba0e6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
