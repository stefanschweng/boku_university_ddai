{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d54e5726-3c30-45ca-b988-1fed78a14036",
   "metadata": {},
   "source": [
    "# Forest Covertype\n",
    "\n",
    "Classification of pixels into 7 forest cover types based on attributes such as elevation, aspect, slope, hillshade, soil-type, and more.\n",
    "Dataset available [here](https://archive.ics.uci.edu/dataset/31/covertype).\n",
    "\n",
    "## General Information\n",
    "Predicting forest cover type from cartographic variables only (no remotely sensed data).  The actual forest cover type for a given observation (30 x 30 meter cell) was determined from US Forest Service (USFS) Region 2 Resource Information System (RIS) data.  Independent variables were derived from data originally obtained from US Geological Survey (USGS) and USFS data.  Data is in raw form (not scaled) and contains binary (0 or 1) columns of data for qualitative independent variables (wilderness areas and soil types).\n",
    "\n",
    "This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado.  These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices.\n",
    "\n",
    "Some background information for these four wilderness areas: Neota (area 2) probably has the highest mean elevational value of the 4 wilderness areas. Rawah (area 1) and Comanche Peak (area 3) would have a lower mean elevational value, while Cache la Poudre (area 4) would have the lowest mean elevational value. \n",
    "\n",
    "As for primary major tree species in these areas, Neota would have spruce/fir (type 1), while Rawah and Comanche Peak would probably have lodgepole pine (type 2) as their primary species, followed by spruce/fir and aspen (type 5). Cache la Poudre would tend to have Ponderosa pine (type 3), Douglas-fir (type 6), and cottonwood/willow (type 4).  \n",
    "\n",
    "The Rawah and Comanche Peak areas would tend to be more typical of the overall dataset than either the Neota or Cache la Poudre, due to their assortment of tree species and range of predictive variable values (elevation, etc.)  Cache la Poudre would probably  be more unique than the others, due to its relatively low  elevation range and species composition. \n",
    "\n",
    "## Additional Variable Information\n",
    "Given is the attribute name, attribute type, the measurement unit and a brief description.  The forest cover type is the classification  problem.  The order of this listing corresponds to the order of numerals along the rows of the database.\n",
    "\n",
    "|Name | Data Type | Measurement | Description|\n",
    "|-----|-----------|-------------|------------|\n",
    "|Elevation | quantitative |meters | Elevation in meters|\n",
    "|Aspect | quantitative | azimuth | Aspect in degrees azimuth|\n",
    "|Slope | quantitative | degrees | Slope in degrees|\n",
    "|Horizontal_Distance_To_Hydrology | quantitative | meters | Horz Dist to nearest surface water features|\n",
    "|Vertical_Distance_To_Hydrology | quantitative | meters | Vert Dist to nearest surface water features|\n",
    "|Horizontal_Distance_To_Roadways | quantitative | meters | Horz Dist to nearest roadway|\n",
    "|Hillshade_9am | quantitative | 0 to 255 index | Hillshade index at 9am, summer solstice|\n",
    "|Hillshade_Noon | quantitative | 0 to 255 index | Hillshade index at noon, summer soltice|\n",
    "|Hillshade_3pm | quantitative | 0 to 255 index | Hillshade index at 3pm, summer solstice|\n",
    "|Horizontal_Distance_To_Fire_Points | quantitative | meters | Horz Dist to nearest wildfire ignition points|\n",
    "|Wilderness_Area (4 binary columns) | qualitative | 0 (absence) or 1 (presence) | Wilderness area designation|\n",
    "|Soil_Type (40 binary columns) | qualitative | 0 (absence) or 1 (presence) | Soil Type designation|\n",
    "|Cover_Type (7 types) | integer | 1 to 7 | Forest Cover Type designation|\n",
    "\n",
    "## Class labels\n",
    "Spruce/Fir, Lodgepole Pine, Ponderosa Pine, Cottonwood/Willow, Aspen, Douglas-fir, Krummholz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18059a59-f6cd-4993-9998-b5c31a406632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184638909160417394d8ed967350d089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(VBox(children=(HTML(value='<h2>Forest Covertype Subset Loading and Visualization…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive ML playground for the Forest Covertype dataset (scikit-learn \"covtype\")\n",
    "# Single-cell Jupyter code using ipywidgets\n",
    "# Requirements: scikit-learn, ipywidgets, pandas, numpy\n",
    "# If widgets do not render, ensure: pip install ipywidgets && jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, balanced_accuracy_score\n",
    ")\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "#########################################################################################################################\n",
    "####################################### DATASET #########################################################################\n",
    "#########################################################################################################################\n",
    "# -----------------------------\n",
    "# Load dataset once\n",
    "# -----------------------------\n",
    "covtype = fetch_covtype(as_frame=False)\n",
    "X_all, y_all = covtype.data, covtype.target\n",
    "X_all = X_all.astype(np.float32)\n",
    "\n",
    "# Stratified split to preserve class distribution\n",
    "X, _, y, _ = train_test_split(\n",
    "    X_all, y_all, train_size=0.1, stratify=y_all, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Widgets\n",
    "# -----------------------------\n",
    "class_groups = {\n",
    "    \"Subset A\": [1, 2, 5],\n",
    "    \"Subset B\": [4, 5, 7],\n",
    "    \"Subset C\": [3, 6, 7],\n",
    "}\n",
    "\n",
    "group_dropdown = widgets.Dropdown(\n",
    "    options=list(class_groups.keys()),\n",
    "    value=\"Subset A\",\n",
    "    description=\"Subset:\",\n",
    ")\n",
    "\n",
    "viz_points = 150 #widgets.IntSlider(\n",
    "#    value=600, min=200, max=3000, step=100, description=\"Max points (pairplot)\"\n",
    "#)\n",
    "\n",
    "run_button = widgets.Button(description=\"Pick subset\", button_style=\"primary\")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "controls = widgets.VBox([\n",
    "    widgets.HTML(\"<h2>Forest Covertype Subset Loading and Visualization</h2>\"),\n",
    "    widgets.HBox([group_dropdown]),\n",
    "    #widgets.HBox([viz_points, show_pairplot]),\n",
    "    run_button\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# Helper: balanced subsample per class\n",
    "# -----------------------------\n",
    "def balanced_subsample(Xs, ys, max_total=600, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    classes, counts = np.unique(ys, return_counts=True)\n",
    "    per_class = max_total // len(classes) if len(classes) > 0 else max_total\n",
    "    idx_all = []\n",
    "    for c in classes:\n",
    "        idx_c = np.where(ys == c)[0]\n",
    "        take = min(len(idx_c), per_class)\n",
    "        if take > 0:\n",
    "            chosen = rng.choice(idx_c, size=take, replace=False)\n",
    "            idx_all.append(chosen)\n",
    "    if len(idx_all) == 0:\n",
    "        return Xs[:0], ys[:0]\n",
    "    idx_all = np.concatenate(idx_all)\n",
    "    rng.shuffle(idx_all)\n",
    "    return Xs[idx_all], ys[idx_all]\n",
    "\n",
    "# -----------------------------\n",
    "# Main runner\n",
    "# -----------------------------\n",
    "def run_dataset(*args):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        selected = class_groups[group_dropdown.value]\n",
    "        mask = np.isin(y, selected)\n",
    "        X_sub = X[mask]\n",
    "        y_sub = y[mask]\n",
    "\n",
    "        global X_train, X_test, y_train, y_test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_sub, y_sub, test_size=0.2, stratify=y_sub, random_state=42\n",
    "        )\n",
    "\n",
    "        present_classes = np.unique(y_sub)\n",
    "        print(f\"Requested classes: {selected}\")\n",
    "        print(f\"Present classes in dataset: {present_classes.tolist()}\")\n",
    "        if len(X_sub) == 0:\n",
    "            print(\"No samples found for the selected class group. Try a different selection.\")\n",
    "            return\n",
    "\n",
    "        # Summary\n",
    "        counts = {int(c): int((y_sub == c).sum()) for c in present_classes}\n",
    "        print(f\"Subset size: {len(X_sub)} samples\")\n",
    "        print(f\"Class counts: {counts}\")\n",
    "\n",
    "        # Correlation heatmap for first 10 features (across the subset)\n",
    "        #cols = [f\"f{i}\" for i in range(10)]\n",
    "        cols = [\n",
    "            'Elevation',\n",
    "            'Aspect',\n",
    "            'Slope',\n",
    "            'HDist_Hydro',\n",
    "            'VDist_Hydro',\n",
    "            'HDist_Road',\n",
    "            'Hillsh_9am',\n",
    "            'Hillsh_Noon',\n",
    "            'Hillsh_3pm',\n",
    "            'HDist_FirePts'\n",
    "        ]\n",
    "        df10 = pd.DataFrame(X_sub[:, :10], columns=cols)\n",
    "        corr = df10.corr(method=\"pearson\")\n",
    "\n",
    "        X_vis, y_vis = balanced_subsample(X_sub, y_sub, max_total=viz_points, seed=42)\n",
    "        if len(X_vis) == 0:\n",
    "            print(\"Not enough samples to create pairplot.\")\n",
    "            return\n",
    "        df_vis = pd.DataFrame(X_vis[:, :10], columns=cols)\n",
    "        df_vis[\"class\"] = y_vis.astype(int)\n",
    "\n",
    "        # Use corner=True to reduce complexity of the grid\n",
    "        g = sns.pairplot(\n",
    "            df_vis, vars=cols, hue=\"class\", corner=True,\n",
    "            plot_kws={\"s\": 10, \"alpha\": 0.6},\n",
    "            diag_kind=\"kde\"\n",
    "        )\n",
    "        g.fig.set_size_inches(12, 12)\n",
    "        g.fig.suptitle(\"Pairplot (first 10 features, colored by class, subsampled)\", y=1.02)\n",
    "        plt.show()\n",
    "\n",
    "run_button.on_click(run_dataset)\n",
    "\n",
    "\n",
    "data_ui = widgets.VBox([controls, output])\n",
    "\n",
    "\n",
    "#########################################################################################################################\n",
    "####################################### MODEL ###########################################################################\n",
    "#########################################################################################################################\n",
    "\n",
    "# -----------------------------\n",
    "# Utility: build preprocessor\n",
    "# -----------------------------\n",
    "def make_preprocessor(choice):\n",
    "    if choice == \"None\":\n",
    "        return None\n",
    "    if choice == \"Center\":\n",
    "        return StandardScaler(with_mean=True, with_std=False)\n",
    "    if choice == \"Scale\":\n",
    "        return StandardScaler(with_mean=False, with_std=True)\n",
    "    if choice == \"Center & Scale\":\n",
    "        return StandardScaler()\n",
    "    if choice == \"Normalize (L2)\":\n",
    "        return Normalizer(norm=\"l2\")\n",
    "    raise ValueError(f\"Unknown preprocessing option: {choice}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Utility: balance training set by random undersampling to smallest class count\n",
    "# -----------------------------\n",
    "def balance_training(Xt, yt, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    classes, counts = np.unique(yt, return_counts=True)\n",
    "    #n = counts.min()\n",
    "    n = int(counts.mean())\n",
    "    idx_list = []\n",
    "    for c in classes:\n",
    "        idx_c = np.where(yt == c)[0]\n",
    "        if len(idx_c) < n:\n",
    "            chosen = rng.choice(idx_c, size=n, replace=True)\n",
    "        else:\n",
    "            chosen = rng.choice(idx_c, size=n, replace=False)\n",
    "        idx_list.append(chosen)\n",
    "    idx_all = np.concatenate(idx_list)\n",
    "    rng.shuffle(idx_all)\n",
    "    return Xt[idx_all], yt[idx_all]\n",
    "\n",
    "# -----------------------------\n",
    "# Widgets: Data Preparation\n",
    "# -----------------------------\n",
    "preproc_dropdown = widgets.Dropdown(\n",
    "    options=[\"None\", \"Center\", \"Scale\", \"Center & Scale\", \"Normalize (L2)\"],\n",
    "    value=\"Center & Scale\",\n",
    "    description=\"Preprocess:\",\n",
    ")\n",
    "\n",
    "balance_checkbox = widgets.Checkbox(\n",
    "    value=False, description=\"Balance training samples\"\n",
    ")\n",
    "\n",
    "data_prep_box = widgets.VBox([preproc_dropdown, balance_checkbox])\n",
    "\n",
    "# -----------------------------\n",
    "# Widgets: Feature Selection (columns 0..9)\n",
    "# -----------------------------\n",
    "#feature_checkboxes = [widgets.Checkbox(value=True, description=f\"Col {i}\") for i in range(10)]\n",
    "feature_checkboxes = [widgets.Checkbox(value=True, description=f\"{i}\") for i in covtype.feature_names[:10]]\n",
    "# Arrange in two rows for readability\n",
    "feature_selection_box = widgets.VBox([\n",
    "    widgets.HBox(feature_checkboxes[:3]),\n",
    "    widgets.HBox(feature_checkboxes[3:6]),\n",
    "    widgets.HBox(feature_checkboxes[6:9]),\n",
    "    widgets.HBox(feature_checkboxes[9:]),\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# Widgets: Model Selection\n",
    "# -----------------------------\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=[\"Logistic Regression\", \"MLP\", \"Decision Tree\", \"Random Forest\"],\n",
    "    value=\"Logistic Regression\",\n",
    "    description=\"Model:\",\n",
    ")\n",
    "\n",
    "# Model-dependent complexity controls\n",
    "mlp_neurons = widgets.IntSlider(value=64, min=8, max=512, step=8, description=\"# Neurons\")\n",
    "dt_max_depth = widgets.IntSlider(value=20, min=2, max=50, step=1, description=\"Max depth\")\n",
    "rf_n_estimators = widgets.IntSlider(value=100, min=10, max=300, step=10, description=\"# Trees\")\n",
    "rf_max_depth = widgets.IntSlider(value=20, min=2, max=50, step=1, description=\"Max depth\")\n",
    "\n",
    "complexity_box = widgets.VBox([])\n",
    "\n",
    "def update_complexity_controls(*args):\n",
    "    mdl = model_dropdown.value\n",
    "    if mdl == \"Logistic Regression\":\n",
    "        complexity_box.children = [widgets.HTML(\"<i>No complexity slider for Logistic Regression.</i>\")]\n",
    "    elif mdl == \"MLP\":\n",
    "        complexity_box.children = [mlp_neurons]\n",
    "    elif mdl == \"Decision Tree\":\n",
    "        complexity_box.children = [dt_max_depth]\n",
    "    elif mdl == \"Random Forest\":\n",
    "        complexity_box.children = [rf_n_estimators, rf_max_depth]\n",
    "\n",
    "model_dropdown.observe(update_complexity_controls, names=\"value\")\n",
    "update_complexity_controls()\n",
    "\n",
    "model_selection_box = widgets.VBox([model_dropdown, complexity_box])\n",
    "\n",
    "# -----------------------------\n",
    "# Widgets: Model Training & Hyperparameter Tuning (regularization)\n",
    "# -----------------------------\n",
    "# Logistic Regression regularization\n",
    "lr_C = widgets.FloatLogSlider(\n",
    "    value=1.0, base=10, min=-2, max=2, step=0.1, description=\"LR C (1/λ)\"\n",
    ")\n",
    "\n",
    "# MLP regularization\n",
    "mlp_alpha = widgets.FloatLogSlider(\n",
    "    value=1e-4, base=10, min=-6, max=-1, step=0.1, description=\"MLP α (L2)\"\n",
    ")\n",
    "\n",
    "# Decision Tree regularization (cost-complexity pruning alpha)\n",
    "dt_ccp_alpha = widgets.FloatSlider(\n",
    "    value=0.0, min=0.0, max=0.05, step=0.001, description=\"DT ccp_alpha\"\n",
    ")\n",
    "\n",
    "# Random Forest regularization-ish\n",
    "rf_min_samples_leaf = widgets.IntSlider(\n",
    "    value=1, min=1, max=20, step=1, description=\"RF min_samples_leaf\"\n",
    ")\n",
    "\n",
    "tuning_box = widgets.VBox([])\n",
    "\n",
    "def update_tuning_controls(*args):\n",
    "    mdl = model_dropdown.value\n",
    "    if mdl == \"Logistic Regression\":\n",
    "        tuning_box.children = [lr_C]\n",
    "    elif mdl == \"MLP\":\n",
    "        tuning_box.children = [mlp_alpha]\n",
    "    elif mdl == \"Decision Tree\":\n",
    "        tuning_box.children = [dt_ccp_alpha]\n",
    "    elif mdl == \"Random Forest\":\n",
    "        tuning_box.children = [rf_min_samples_leaf]\n",
    "\n",
    "model_dropdown.observe(update_tuning_controls, names=\"value\")\n",
    "update_tuning_controls()\n",
    "\n",
    "# -----------------------------\n",
    "# Containers with block titles\n",
    "# -----------------------------\n",
    "data_prep_section = widgets.VBox([widgets.HTML(\"<h3>Data Preparation</h3>\"), data_prep_box])\n",
    "feature_selection_section = widgets.VBox([widgets.HTML(\"<h3>Feature Selection</h3>\"), feature_selection_box])\n",
    "model_selection_section = widgets.VBox([widgets.HTML(\"<h3>Model Selection</h3>\"), model_selection_box])\n",
    "tuning_section = widgets.VBox([widgets.HTML(\"<h3>Model Training & Hyperparameter Tuning</h3>\"), tuning_box])\n",
    "\n",
    "# Optionally use Accordion\n",
    "accordion = widgets.Accordion(children=[\n",
    "    data_prep_box, feature_selection_box, model_selection_box, tuning_box\n",
    "])\n",
    "accordion.set_title(0, \"Data Preparation\")\n",
    "accordion.set_title(1, \"Feature Selection\")\n",
    "accordion.set_title(2, \"Model Selection\")\n",
    "accordion.set_title(3, \"Model Training & Hyperparameter Tuning\")\n",
    "#accordion = widgets.VBox([\n",
    "#    data_prep_box, feature_selection_box, model_selection_box, tuning_box\n",
    "#])\n",
    "\n",
    "# -----------------------------\n",
    "# Output and run controls\n",
    "# -----------------------------\n",
    "run_button = widgets.Button(description=\"Train\", button_style=\"success\")\n",
    "output = widgets.Output()\n",
    "\n",
    "# -----------------------------\n",
    "# Build model pipeline based on UI\n",
    "# -----------------------------\n",
    "def build_classifier():\n",
    "    mdl = model_dropdown.value\n",
    "    if mdl == \"Logistic Regression\":\n",
    "        clf = LogisticRegression(\n",
    "            C=lr_C.value,\n",
    "            penalty=\"l2\",\n",
    "            solver=\"lbfgs\",\n",
    "            max_iter=200,\n",
    "            #multi_class=\"auto\",\n",
    "            random_state=42\n",
    "        )\n",
    "    elif mdl == \"MLP\":\n",
    "        clf = MLPClassifier(\n",
    "            hidden_layer_sizes=(mlp_neurons.value,),\n",
    "            activation=\"relu\",\n",
    "            solver=\"adam\",\n",
    "            alpha=mlp_alpha.value,\n",
    "            max_iter=50,\n",
    "            early_stopping=True,\n",
    "            random_state=42\n",
    "        )\n",
    "    elif mdl == \"Decision Tree\":\n",
    "        clf = DecisionTreeClassifier(\n",
    "            max_depth=dt_max_depth.value,\n",
    "            ccp_alpha=dt_ccp_alpha.value,\n",
    "            random_state=42\n",
    "        )\n",
    "    elif mdl == \"Random Forest\":\n",
    "        clf = RandomForestClassifier(\n",
    "            n_estimators=rf_n_estimators.value,\n",
    "            max_depth=rf_max_depth.value,\n",
    "            min_samples_leaf=rf_min_samples_leaf.value,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    return clf\n",
    "\n",
    "# -----------------------------\n",
    "# Run experiment on button click\n",
    "# -----------------------------\n",
    "def run_experiment(*args):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        # Feature selection: collect selected columns\n",
    "        selected_cols = [i for i, cb in enumerate(feature_checkboxes) if cb.value]\n",
    "        if len(selected_cols) == 0:\n",
    "            print(\"Please select at least one feature (column 0..9).\")\n",
    "            return\n",
    "\n",
    "        # Slice features\n",
    "        Xtr = X_train[:, selected_cols + list(range(10,54))]\n",
    "        Xte = X_test[:, selected_cols + list(range(10,54))]\n",
    "\n",
    "        # Balance training set if requested\n",
    "        if balance_checkbox.value:\n",
    "            Xtr_bal, ytr_bal = balance_training(Xtr, y_train, seed=42)\n",
    "        else:\n",
    "            Xtr_bal, ytr_bal = Xtr, y_train\n",
    "\n",
    "        # Build pipeline\n",
    "        preproc = make_preprocessor(preproc_dropdown.value)\n",
    "        clf = build_classifier()\n",
    "        steps = []\n",
    "        if preproc is not None:\n",
    "            steps.append((\"preprocess\", preproc))\n",
    "        steps.append((\"clf\", clf))\n",
    "        pipe = Pipeline(steps)\n",
    "\n",
    "        # Train\n",
    "        t0 = time.perf_counter()\n",
    "        pipe.fit(Xtr_bal, ytr_bal)\n",
    "        t_train = time.perf_counter() - t0\n",
    "\n",
    "        # Predict\n",
    "        t1 = time.perf_counter()\n",
    "        y_pred = pipe.predict(Xte)\n",
    "        t_pred = time.perf_counter() - t1\n",
    "\n",
    "        # Metrics\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "        f1m = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # Report\n",
    "        print(\"=== Configuration ===\")\n",
    "        print(f\"Selected features: {selected_cols} (count={len(selected_cols)})\")\n",
    "        print(f\"Preprocessing: {preproc_dropdown.value}\")\n",
    "        print(f\"Balanced training: {balance_checkbox.value}\")\n",
    "        print(f\"Model: {model_dropdown.value}\")\n",
    "        if model_dropdown.value == \"MLP\":\n",
    "            print(f\" - Neurons: {mlp_neurons.value}, alpha={mlp_alpha.value:g}\")\n",
    "        elif model_dropdown.value == \"Decision Tree\":\n",
    "            print(f\" - Max depth: {dt_max_depth.value}, ccp_alpha={dt_ccp_alpha.value:g}\")\n",
    "        elif model_dropdown.value == \"Random Forest\":\n",
    "            print(f\" - Trees: {rf_n_estimators.value}, Max depth: {rf_max_depth.value}, min_samples_leaf={rf_min_samples_leaf.value}\")\n",
    "        elif model_dropdown.value == \"Logistic Regression\":\n",
    "            print(f\" - C (1/λ): {lr_C.value:g}\")\n",
    "\n",
    "        print(\"\\n=== Performance (test set) ===\")\n",
    "        print(f\"Accuracy: {acc:.4f}\")\n",
    "        print(f\"Precision (macro): {prec:.4f}\")\n",
    "        print(f\"Recall (macro): {rec:.4f}\")\n",
    "        print(f\"F1-score (macro): {f1m:.4f}\")\n",
    "        print(f\"Balanced accuracy: {balanced_accuracy_score(y_test, y_pred):.4f}\")\n",
    "        print(f\"\\nTraining time: {t_train:.3f} s\")\n",
    "        print(f\"Inference time (predict): {t_pred:.3f} s\")\n",
    "\n",
    "        #print(\"\\nConfusion matrix (rows: true, cols: predicted):\")\n",
    "        #cm_df = pd.DataFrame(cm)\n",
    "        #display(cm_df)\n",
    "        \n",
    "        print(\"\\nConfusion matrix:\")\n",
    "        labels = np.unique(y_test)\n",
    "        fig, ax = plt.subplots(figsize=(5, 5), dpi=120)\n",
    "        disp = ConfusionMatrixDisplay.from_predictions(\n",
    "            y_test, y_pred, cmap=\"Blues\", normalize='true', values_format='.3f', colorbar=True, ax=ax\n",
    "        )\n",
    "        ax.set_title(\"Confusion Matrix\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "run_button.on_click(run_experiment)\n",
    "\n",
    "# -----------------------------\n",
    "# Display UI\n",
    "# -----------------------------\n",
    "ui = widgets.VBox([\n",
    "    widgets.HTML(\"<h2>Forest Covertype ML Playground</h2>\"),\n",
    "    accordion,\n",
    "    widgets.HBox([run_button]),\n",
    "    output\n",
    "])\n",
    "\n",
    "display(widgets.VBox([data_ui, ui]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54964df-b7e4-4136-91c7-fd03500c8eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
